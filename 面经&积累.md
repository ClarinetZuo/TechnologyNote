# 阿里面经---20190315 19:19呼入，持续41min，酸爽(蚂蚁金服一面)
## 自我介绍
## 谈谈自己对大数据，Hadoop的理解，介绍了一下HDFS和MR
## 如果你是MR的设计者，在MR时，如何和NameNode通信
## 情景分析：
- 项目中的HQL转换为MR，会出现数据倾斜的问题;比如top10问题，会在一台机器算每个key的top10，如果想全局有序，再来一个MR，设置一个Reducer即可
- 两道sql，应该是都说对了，第二个在提示下做了出来，使用over(partition by)
## MR出现数据倾斜，怎么办？
## 作为一个Kafka或者消息队列的设计者，需要为用户考虑哪些东西？
## 设计模式：单例、工厂。说说单例的几种实现方式
## 线程安全的类
- CopyOnWriteArrayList ConcurrentHashMap volatile关键字 Atomic类
- 什么时候用Atomic类？
# 20190318 17:15呼入 持续33min，没有自我介绍，上来就怼(蚂蚁金服二面)
## 说说大数据
## Spark和Hadoop的相同点、不同点
## 怼项目，MR的key和value 都是啥，RowKey的设计
## ArrayList并发时产生的问题，那些个集合什么时候用
## MySQL事务，事务隔离级别
## 两条sql，秒了；秒个jb秒，真tm难受
	`create or replace view vmayi as (
		select userId,count(userId) countM,cityName from mayi group by cityName,userId);

	select t.userId,t.cityName from (
	select *,row_number() over(partition by cityName order by countM desc) rank1 from vmayi) t where t.rank1 <= 3`;
# 小米一面
## 比较简单，一个问题较为疑惑，HBase适合用于什么场景中？
## 瞬时写入量极大的情况
## 不需要复杂查询条件来查询数据的应用中
## 不需要关联的场景中，HBase是NoSQL，无法支持join
## 可靠性要求高：因为HRegionServer宕机，region会在线分配给其他机器;HMaster支持HA;数据会持久化在HLog和HDFS
## 数据量较大，HBase支持在线扩展
## 生产环境关闭split，region数不要太多
# 小米二面
## Kafka的两种消息传送模式
## 深度学习了解过吗
## JMM说一下
## 锁说一下
# 十一贝乱面
## HiveQL如何转换为MR?说出来了
## 一致性哈希了解吗?不了解
## 归并排序会不会?不会欧耶
# 小红书一面(56min)
## 项目中为什么用Flume？
## 一条很难的sql
## 电信项目，做实时数据展示，可以用Redis，可是我不会
## 两道算法，第一道动态规划不会；第二道用Stack简单些
# 海康威视一面(27min)
## Kafka的At most once && At least one
## ZooKeeper在Kafka和HBase中的作用
## HBase的Region设置多大合适
## HashMap源码
## volatile关键字->无法保证变量的原子性
## 线程同步的几种方式
## ConcurrentHashMap简单问了问
## ReentrantLock的优化->分段锁
## 面试官说synchronized不是可重入锁，Hadoop的HA没有脑裂现象
# 松果二面
## Hive中什么情况有可能出现数据倾斜，我说了count(disinct 某个字段) 有可能出现数据倾斜，然而他问我为什么的时候，我没答上来，通过查资料，答案如下
- count(distinct 某个字段)时，会在一个reducer里面完成，数据量大时，严重数据倾斜
- 解决方法：现将这个字段subString，然后group by，这样会多开一个MR Job，但在数据量大的时候，很值得，举个例子：
```sql
SELECT SUM(mau_part) mau FROM 
( -- 内层SELECT分别进行COUNT(DISTINCT)计算 
SELECT substr(uuid, 1, 3) uuid_part, 
COUNT(DISTINCT substr(uuid, 4)) AS mau_part FROM 
detail_sdk_session 
WHERE partition_date >= '2016-01-01' AND partition_date <= now 
GROUP BY substr(uuid, 1, 3) ) t;
```
**uuid是一个16位的用户id，原始的sql是这样的：select count(disinct uuid) a from detail_sdk_session**
# 积累
## 关于String的小知识
```Java
String str1 = "str";
String str2 = "ing";
String str3 = "str"+"ing";
String str4 = str1+str2;
String str5 = "string";
System.out.println(str3 == str4); // false 因为，str4会在堆中创建
System.out.println(str3 == str5); // true 都在字符串常量池中
System.out.println(str4 == str5); // false
```
## 关于ConcurrentModificationException
### 什么时候会抛出这个异常？
#### 以ArrayList为例，当使用增强的for循环遍历这个集合的同时，使用list.remove()来删除集合中的元素，就会抛出这个异常
```Java
List<String> list = new ArrayList<>();        
list.add("1");
list.add("2");
list.add("3");
list.add("4");
list.add("5");
list.add("6");
for (String s:list) {
	if (s.equals("2")){
		list.remove(s);
	}
}
```
### 抛异常的原因：因为调用增强的for循环，就是在调用ArrayList中的内部类Itr，Itr内部会维护一个expectedModCount，也就是迭代器期望修改的次数，而每次在使用list的add remove方法时，都会修改List本身的modCount，当expectedModCount != modCount的时候，就会抛出该异常
### 遍历时就不能删除吗？答案当然是否定的
- 可以使用Iterator的remove方法
- 看一段代码
```Java
List<String> list = new ArrayList<>();
        
list.add("1");
list.add("2");
list.add("3");
list.add("4");
list.add("5");
list.add("6");

for (String s:list) {
		if (s.equals("5")){
				list.remove(s);
		}
}
```
- 当删除倒数第二个元素的时候，永远不会抛异常，为啥？？因为追溯到源码，异常的抛出是在Itr的next()方法中的checkForComodification()，而什么时候才会触发next()方法呢，就是hasNext()返回true的时候，所以让hasNext()返回false即可，所以当遍历到倒数第二个元素时，游标指向最后一个索引，hasNext()就是false，就不会调用next()方法，从而不会抛出ConcurrentModificationException
## 关于Linux中的crontab(定时任务)
- 几个基本的命令：crontab [-l] [-e] [-d]
- 从左往右五个*依次表示：分 时 日 月 周
## 关于Spark中的宽窄依赖
- 窄依赖：父级RDD中的一个partition最多被子级RDD中的一个partition所利用；e.g. map filter union等，其中类似map和filter这种算子都是OneToOneDependencies，union是RangeDependencies
- 宽依赖：父级RDD中的一个partition被子级多个RDD中的partition所利用；e.g. groupByKey reduceByKey 某些join；这里的某些join指的是join之前没有groupByKey的join，详见博客：https://blog.csdn.net/m0_37657725/article/details/94969024
## 关于sql语句中的排名函数
- row_number():正常排名 1 2 3 无论排名依据是否相等
- rank()：非密集排名 当出现并列的时候 1 1 3
- dense_rank()：密集排名 当出现并列的时候 1 1 2
## 关于ArrayList的SubList
- 功能：截取集合中某个索引到某个索引的元素，并返回一个**ArrayList$SubList,SubList是ArrayList的一个成员内部类**
- 如果改变对应SubList中的元素，对应的ArrayList也会跟着改变，代码如下
```Java
List<Integer> list = new ArrayList<>();
	list.add(1);
	list.add(2);
	list.add(3);
	list.add(4);
	list.add(5);

	List<Integer> subList = list.subList(0,2);
	subList.remove(0);
	System.out.println(list); // [2,3,4,5]，所以**千万小心**
```
## 关于Collections.sort()自定义比较器的1和-1的记法
```Java
List<Integer> list = new ArrayList<>();
list.add(5);
list.add(6);
list.add(1);
list.add(2);
Collections.sort(list, new Comparator<Integer>() {
	@Override
	public int compare(Integer o1, Integer o2) {
		return o1 < o2 ? 1 : -1; // o1小于o2，返回1，说明要调整顺序，也就是把小的往后调整，也就是倒序
		return o1 < o2 ? -1 : 1; //o1小于o2，返回-1，说明不调整顺序，也就是小的还在前面，也就是升序
	}
});
```
### 1记为调整顺序也就是true；-1记为不调整顺序也就是false
## 关于Thompson采样和Beta分布
- Thompson采样采用Beta分布来描述收益率的分布，对于一个item来说，用户点击了一次wins + 1，用户没点的话，lose + 1
- betaSample(win,lose) -> 预估出一个item带来的收益 -> 按照这个revenue进行倒排可以选出收益item的topN
## 关于Git
- 查看本地分支和追踪情况：git remote show origin：可以看到一些stale的分支，这是远程已经删除的分支，但没同步到你的机器
- 使用 git remote prune origin去同步远程分支
- 最后使用 git branch -D 本地分支来删除本地分支
## 关于Spark的作业调度模型
- 每一个action算子提交job
- 根据job的宽窄依赖划分stage
- 根据stage中RDD的partition划分task
- Driver进程分发task到worker节点，Executor进程负责执行task
## 关于Spark中的累加器和广播变量
### 累加器
- Spark在操作和传递一个函数时，比如map，reduce等等，它会在远程集群中的一个节点执行，且操作的是**变量的副本**，且这些副本不能传回Driver进程，因此结果Driver进程拿不到，所以累机器和共享变量应运而生
- 累加器：Accumulator，Spark中的累加器主要有两种，Double和Long，还有个collection
 ```scala
 val doubleAcc = sc.doubleAccumulator
 val longAcc = sc.longAccumulator
 val collectionAcc = sc.collectionAccumulator
 doubleAcc.add(1.0)
 ```
**有名字和没有名字的累加器的区别在于，是否可以在WebUI上看到**
**由于Spark是lazy加载的，所以需要一个action算子提交job之后，累加器才会计算，注意，只能提交一次，否则会出现多加的情况，如果不得不提交两次，可以将前一次的结果通过持久化策略保存下来，避免计算两次**
**自定义累加器需extends AccumulatorV2，且使用时向sc注册**
### 广播变量
- 什么时候使用广播变量？比如Driver上面有一张表，其他节点运行的task都需要join这张表，好的方式是将这张表copy到每个节点，本地join，这就是广播变量
- 广播变量将变量广播到每个节点而不是task。因为每个task是一个线程，同一个Executor进程的task同属于一个application，，因此广播到每个节点即可。
## 关于j.u.c中的阻塞队列
### 阻塞队列有这么几个方法：
```Java
queue.add(); //内部调用offer，当队列满了的时候，抛出异常
queue.offer(); // 向队尾添加元素，当队列满了的时候，返回false
queue.put(); // 队列满了，会等待
queue.remove(); // 对应add
queue.poll(); // 对应offer，删除队首的元素
queue.take(); // 对应put
```
- ArrayBlockingQueue:内部基于数组实现，读写不分离，默认构造方法需要传递参数表示容量
- LinkedBlockingQueue:内部基于链表实现，读写分离，默认构造方法不需要传参但不代表其实无界的阻塞队列，它默认的界限是**Integer.MAX_VALUE**
- PriorityBlockingQueue:是一个带优先级的有界阻塞队列(**默认的容量是11**)，可以实现自定义排序
- DelayQueue:元素需要实现Delayed接口，无界
- SynchronousQueue:只存储一个元素；无界非缓存队列
## Java内存模型
### 为什么要提出Java内存模型(Java Memory Model)：为了屏蔽掉硬件和操作系统对内存访问速度上的差异，真正实现Java的跨平台
### 有以下三个规范：
- Java 内存模型规定所有的变量存在主内存（虚拟机内存的一部分）每条线程还有自己的工作内存 线程的工作内存保存了该线程使用到的变量和主内存副本拷贝，线程对变量的所有操作（读取或者赋值）都必须在工作内存，不能直接读写主内存的变量
- 不同线程之间的内存无法直接访问
- 线程间变量值的传递都需要通过主内存
## 关于Kafka的写入数据、丢消息以及重复消费
### 写入消息时候的ACK
- 0：producer将消息发到leader partition就完事，不关心leader partition是否保存成功，可能丢数据
- 1：当写Leader partition成功后就返回,其他的replica都是通过fetcher去同步的,所以kafka是异步写，主备切换可能丢数据。
- -1[ALL]：要等到isr里所有partition同步成功，才能返回成功，延时取决于最慢的机器。强一致，不会丢数据。
- 丢消息产生的原因以及解决方法：Producer向Leader Partition写数据，写完之后，Leader立刻挂了，消息永久丢失，且此时ACK设置的是0。解决方法：将ACK设置1
- 重复消费的产生原因以及解决方法：由于网络原因，导致生产者提交消息接收不到提交成功的反馈，导致消息重传；消费者没有返回消费成功反馈，重复拉取消息消费；
	- 将消息进行落库场景，例如将订单消息进行落库， 根据消息的不重复数据在表中建立这个数据字段的唯一键约束，比如订单号，同一个订单，第一次插入成功，根据唯一约束第二次插入就失败
	- 接到消息写redis场景，调用set覆盖缓存，天然幂等处理
	- 状态变更类消息，比如订单有三个状态，订单创建、订单支付、订单发货、订单完成，每个state状态对应一个int类型值，消息的state和db相同（反查数据库），不处理；不相同则更新数据表
### 为什么要使用消息队列？
- 流量削峰和缓冲：上游系统有突发流量，而下游系统扛不住瞬时大流量的冲击，或者说下游没有足够的资源来保证冗余，kafka相当于起到一个缓冲作用，把上游系统的消息保存在kafka中，下游系统可以按照自己的节奏来处理。
- 系统间解耦和扩展：将系统间复杂的调用关系解耦出来，多方可以自行决定是否接入kafka来消费信息。
- 异步通信：消息生产者可以将消息存入kafka，消息端可以不用立即处理消息，在需要的时候进行处理。
- 局部顺序消费保证：kafka的partition局部有序，保证了消息是按照顺序排序。
### Kafka的高可用(转载)
- Kafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。
- 这就是天然的分布式消息队列，就是说一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据
- 实际上 RabbmitMQ 之类的，并不是分布式消息队列，它就是传统的消息队列，只不过提供了一些集群、HA(High Availability, 高可用性) 的机制而已，因为无论怎么玩儿，RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。
- Kafka 0.8 以前，是没有 HA 机制的，就是任何一个 broker 宕机了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言。
- 比如说，我们假设创建了一个 topic，指定其 partition 数量是 3 个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 的 1/3 的数据就丢了，因此这个是做不到高可用的。Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader？很简单，要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题，系统复杂度太高，很容易出问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。
- 这么搞，就有所谓的高可用性了，因为如果某个 broker 宕机了，没事儿，那个 broker上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中重新选举一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。
- 写数据的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）
- 消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。
## 星型模型和雪花模型
### 事实表和维度表
- 事实表：存储有事实记录的表，比如系统日志等等
- 维度表：保存维度的属性值，比如日期表、地区表等
### 星型模型
- 一张事实表，以及零到多个维度表，事实表和维度表通过主外键关系相关联，维度表之间无关联
### 雪花模型
- 将星型模型中的某些维度表抽取成为更细粒度的维度表，并让维度之间关联
## ACL Access Control List
## 关于Spark中的aggregateByKey
```Scala
val conf = new SparkConf()
    val sc = new SparkContext(conf)

    val data = sc.parallelize(List(("13909029812",("20170507","http://www.baidu.com")),("18089376778",("20170401","http://www.google.com")),("18089376778",("20170508","http://www.taobao.com")),("13909029812",("20170507","http://www.51cto.com"))
    ))

    data.aggregateByKey(scala.collection.mutable.Set[(String, String)]())((set, item) => {
      set += item
    }, (set1, set2) => set1 union set2).mapValues(x => x.toIterable).collect
```
- 第一个参数：new一个Set集合
- 第二个参数：将value塞进set里面
- 第三个参数：set之间做规约
## Java中的内存泄露
### 指程序中动态分配内存给一些临时对象，但是对象不会被GC所回收，它始终占用内存。即被分配的对象可达但已无用。
## 设计模式(单例、生产者消费者)
### 单例模式的几种代码实现
```Java
// 懒汉模式(无线程安全问题)
public class Singleton{
	private Singletion)(){

	}
	private static Singletion s = new Singleton();
	public Singleton getInstance(){
		return s;
	}
}
```
```Java
// 饿汉模式(存在线程安全问题)
public class Singleton{
	private Singleton(){

	}
	private static Singleton s = null;
	public Singleton getInstance(){
		if (null == s){
			s = new Singleton();
		}
		return s;
	}
}
```
```Java
// 双重校验
public class Singleton{
	private static volatile Singleton s = null;
	private Singleton(){

	}
	public Singleton getInstance(){
		if (null == s){ // 第一重校验，提高效率，别上来就上锁
			synchronized (Singleton.class){
				if (null == s){ // 第二重校验，防止new两次
					s = new Singleton();
				}
			}
		}
		return s;
	}
}
```
```Java
// 静态内部类，由JVM实现线程安全，也能做到类的延迟加载
public class Singleton{
	private Singleton(){

	}
	private static class SingletonHolder{
		private static Singleton s = new Singleton();
	}
	public Singleton getInstance(){
		return SingletonHolder.s;
	}
}
```
### 生产者消费者模式
#### 为什么要有这种模式？？
- 在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这种生产消费能力不均衡的问题，所以便有了生产者和消费者模式。
- 代码实现(使用Lock+Condition)
```Java
class Shop{
	Lock lock = new ReentrantLock();
	Condition condition = lock.newCondition();
	int sum = 0;
	public void make(){
		lock.lock();
		try{
			while (sum <= 0){
				condition.await();
				sum ++;
			}
			condition.signalAll();
		}catch(Exception e){
			
		}finally{
			lock.unlock();
		}
	}
	public void consume(){
		lock.lock();
		try{
			while (sum >= 0){
				condition.await();
				sum --;
			}
			condition.signalAll();
		}finally{
			lock.unlock();
		}
	}
}
class Maker extends Thread{
	Shop shop;
	public Maker(Shop shop){
		this.shop = shop;
	}
	@Override
	public void run(){
		while (true){
			shop.make();
		}
	}
}
class Consumer extends Thread{
	Shop shop;
	public Consumer(Shop shop){
		this.shop = shop;
	}
	@Override
	public void run(){
		while (true){
			shop.consume();
		}
	}
}
```
## Callable的用法
- 直接上代码
```Java
class MyCallable implements Callable<String>{// 这个泛型是自己指定的，根据需求，看你返回值的类型是什么
	public String call() throws InterruptedException{
		// 写点啥都行
		return "success";
	}
}
public static void main(String[] args){
	// 第一种调用方式：借助线程池的submit方法
	ExectorService exec = Executors.newCachedThreadPool();
	Future<String> future = exec.submit(new MyCallable()); // 延伸一个问题，submit中的参数可以是Runnable和Callable，返回值类型都是Future；exec.execute()返回值类型是void且参数类型只能是Runnable
	String result = future.get(); // 注意，这里会将主线程阻塞，是一个异步阻塞
	exec.shutDown(); // 线程池必须手动关闭
}
```
```Java
public static void main(String[] args){
	// 第二种调用方式，借助FutureTask进行包装
	FutureTask<String> task = new FutureTask<String>(new MyCallable());
	new Thread(task).start(); // FutureTask实现了Runnable接口，因此可以作为参数传进去
	String result = task.get(); // 通过FutureTask的get方法可以得到call执行的结果，同时，也是异步阻塞的
}
```
## 关于Linux中的wc命令
```shell
wc -c a.txt：查看这个文件有多少字节
wc -l a.txt：查看这个文件有多少行
wc -w a.txt：查看这个文件有多少个单词，也就是空格个数+1
```
## 关于编译型语言和解释型语言
### 编译型语言：编译型语言首先是将源代码编译生成机器指令，再由机器运行机器码 (二进制)。
- 比如C、C++等
### 解释型语言：解释型语言的源代码不是直接翻译成机器指令，而是先翻译成中间代码，再由解释器对中间代码进行解释运行。
- 比如Java、Python等
## 关于数据库和数据仓库
### 数据库(OLTP)：是一种逻辑概念，是用来存储数据的仓库。是跟业务应用挂钩的，比如实现一个用户的登录功能，数据库中必有一张表，至少两个字段，用户名+密码。
### 数据仓库(OLAP)：是BI(Business Intelligence)商业智能下的一个技术，是面向主题的，一般针对某些主题的历史数据进行分析、决策。
## 关于Spark中的两个算子repartition和coalesce
## coalesce(numPartitions:Int,shuffle:Boolean)
## repartition是coalesce中shuffle参数为true的情况
## 使用时需要注意的点：
### 首先，两个算子都是对RDD进行重新分区
  - 分区前的分区数为N，分区后的分区数为M
  - 如果N<M，一般情况下是N个分区出现数据倾斜的问题，此时shuffle设置为true
  - 如果N > M并且N和M相差不多，(假如N是1000，M是100)那么就可以将N个分区中的若干个分区合并成一个新的分区，最终合并为M个分区，这时可以将shuffle设置为false，在shuffle为false的情况下，如果M>N时，coalesce为无效的，不进行shuffle过程，父RDD和子RDD之间是窄依赖关系。
  - 如果N > M并且两者相差悬殊，这时如果将shuffle设置为false，父子RDD是窄依赖关系，他们同处在一个stage中，就可能造成Spark程序的并行度不够，从而影响性能，如果在M为1的时候，为了使coalesce之前的操作有更好的并行度，可以讲shuffle设置为true。