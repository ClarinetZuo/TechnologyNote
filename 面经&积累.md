# 阿里面经---20190315 19:19呼入，持续41min，酸爽(蚂蚁金服一面)
## 自我介绍
## 谈谈自己对大数据，Hadoop的理解，介绍了一下HDFS和MR
## 如果你是MR的设计者，在MR时，如何和NameNode通信
## 情景分析：
- 项目中的HQL转换为MR，会出现数据倾斜的问题;比如top10问题，会在一台机器算每个key的top10，如果想全局有序，再来一个MR，设置一个Reducer即可
- 两道sql，应该是都说对了，第二个在提示下做了出来，使用over(partition by)
## MR出现数据倾斜，怎么办？
## 作为一个Kafka或者消息队列的设计者，需要为用户考虑哪些东西？
## 设计模式：单例、工厂。说说单例的几种实现方式
## 线程安全的类
- CopyOnWriteArrayList ConcurrentHashMap volatile关键字 Atomic类
- 什么时候用Atomic类？
# 20190318 17:15呼入 持续33min，没有自我介绍，上来就怼(蚂蚁金服二面)
## 说说大数据
## Spark和Hadoop的相同点、不同点
## 怼项目，MR的key和value 都是啥，RowKey的设计
## ArrayList并发时产生的问题，那些个集合什么时候用
## MySQL事务，事务隔离级别
## 两条sql，秒了；秒个jb秒，真tm难受
	`create or replace view vmayi as (
		select userId,count(userId) countM,cityName from mayi group by cityName,userId);

	select t.userId,t.cityName from (
	select *,row_number() over(partition by cityName order by countM desc) rank1 from vmayi) t where t.rank1 <= 3`;
# 小米一面
## 比较简单，一个问题较为疑惑，HBase适合用于什么场景中？
## 瞬时写入量极大的情况
## 不需要复杂查询条件来查询数据的应用中
## 不需要关联的场景中，HBase是NoSQL，无法支持join
## 可靠性要求高：因为HRegionServer宕机，region会在线分配给其他机器;HMaster支持HA;数据会持久化在HLog和HDFS
## 数据量较大，HBase支持在线扩展
## 生产环境关闭split，region数不要太多
# 小米二面
## Kafka的两种消息传送模式
## 深度学习了解过吗
## JMM说一下
## 锁说一下
# 十一贝乱面
## HiveQL如何转换为MR?说出来了
## 一致性哈希了解吗?不了解
## 归并排序会不会?不会欧耶
# 小红书一面(56min)
## 项目中为什么用Flume？
## 一条很难的sql
## 电信项目，做实时数据展示，可以用Redis，可是我不会
## 两道算法，第一道动态规划不会；第二道用Stack简单些
# 海康威视一面(27min)
## Kafka的At most once && At least one
## ZooKeeper在Kafka和HBase中的作用
## HBase的Region设置多大合适
## HashMap源码
## volatile关键字->无法保证变量的原子性
## 线程同步的几种方式
## ConcurrentHashMap简单问了问
## ReentrantLock的优化->分段锁
## 面试官说synchronized不是可重入锁，Hadoop的HA没有脑裂现象
# 松果二面
## Hive中什么情况有可能出现数据倾斜，我说了count(disinct 某个字段) 有可能出现数据倾斜，然而他问我为什么的时候，我没答上来，通过查资料，答案如下
- count(distinct 某个字段)时，会在一个reducer里面完成，数据量大时，严重数据倾斜
- 解决方法：现将这个字段subString，然后group by，这样会多开一个MR Job，但在数据量大的时候，很值得，举个例子：
```sql
SELECT SUM(mau_part) mau FROM 
( -- 内层SELECT分别进行COUNT(DISTINCT)计算 
SELECT substr(uuid, 1, 3) uuid_part, 
COUNT(DISTINCT substr(uuid, 4)) AS mau_part FROM 
detail_sdk_session 
WHERE partition_date >= '2016-01-01' AND partition_date <= now 
GROUP BY substr(uuid, 1, 3) ) t;
```
**uuid是一个16位的用户id，原始的sql是这样的：select count(disinct uuid) a from detail_sdk_session**
# 积累
## 关于String的小知识
```Java
String str1 = "str";
String str2 = "ing";
String str3 = "str"+"ing";
String str4 = str1+str2;
String str5 = "string";
System.out.println(str3 == str4); // false 因为，str4会在堆中创建
System.out.println(str3 == str5); // true 都在字符串常量池中
System.out.println(str4 == str5); // false
```
## 关于ConcurrentModificationException
### 什么时候会抛出这个异常？
#### 以ArrayList为例，当使用增强的for循环遍历这个集合的同时，使用list.remove()来删除集合中的元素，就会抛出这个异常
```Java
List<String> list = new ArrayList<>();        
list.add("1");
list.add("2");
list.add("3");
list.add("4");
list.add("5");
list.add("6");
for (String s:list) {
	if (s.equals("2")){
		list.remove(s);
	}
}
```
### 抛异常的原因：因为调用增强的for循环，就是在调用ArrayList中的内部类Itr，Itr内部会维护一个expectedModCount，也就是迭代器期望修改的次数，而每次在使用list的add remove方法时，都会修改List本身的modCount，当expectedModCount != modCount的时候，就会抛出该异常
### 遍历时就不能删除吗？答案当然是否定的
- 可以使用Iterator的remove方法
- 看一段代码
```Java
List<String> list = new ArrayList<>();
        
list.add("1");
list.add("2");
list.add("3");
list.add("4");
list.add("5");
list.add("6");

for (String s:list) {
		if (s.equals("5")){
				list.remove(s);
		}
}
```
- 当删除倒数第二个元素的时候，永远不会抛异常，为啥？？因为追溯到源码，异常的抛出是在Itr的next()方法中的checkForComodification()，而什么时候才会触发next()方法呢，就是hasNext()返回true的时候，所以让hasNext()返回false即可，所以当遍历到倒数第二个元素时，游标指向最后一个索引，hasNext()就是false，就不会调用next()方法，从而不会抛出ConcurrentModificationException
## 关于Linux中的crontab(定时任务)
- 几个基本的命令：crontab [-l] [-e] [-d]
- 从左往右五个*依次表示：分 时 日 月 周
## 关于Spark中的宽窄依赖
- 窄依赖：父级RDD中的一个partition最多被子级RDD中的一个partition所利用；e.g. map filter union等，其中类似map和filter这种算子都是OneToOneDependencies，union是RangeDependencies
- 宽依赖：父级RDD中的一个partition被子级多个RDD中的partition所利用；e.g. groupByKey reduceByKey 某些join；这里的某些join指的是join之前没有groupByKey的join，详见博客：https://blog.csdn.net/m0_37657725/article/details/94969024
## 关于sql语句中的排名函数
- row_number():正常排名 1 2 3 无论排名依据是否相等
- rank()：非密集排名 当出现并列的时候 1 1 3
- dense_rank()：密集排名 当出现并列的时候 1 1 2
## 关于ArrayList的SubList
- 功能：截取集合中某个索引到某个索引的元素，并返回一个**ArrayList$SubList,SubList是ArrayList的一个成员内部类**
- 如果改变对应SubList中的元素，对应的ArrayList也会跟着改变，代码如下
```Java
List<Integer> list = new ArrayList<>();
	list.add(1);
	list.add(2);
	list.add(3);
	list.add(4);
	list.add(5);

	List<Integer> subList = list.subList(0,2);
	subList.remove(0);
	System.out.println(list); // [2,3,4,5]，所以**千万小心**
```
## 关于Collections.sort()自定义比较器的1和-1的记法
```Java
List<Integer> list = new ArrayList<>();
list.add(5);
list.add(6);
list.add(1);
list.add(2);
Collections.sort(list, new Comparator<Integer>() {
	@Override
	public int compare(Integer o1, Integer o2) {
		return o1 < o2 ? 1 : -1; // o1小于o2，返回1，说明要调整顺序，也就是把小的往后调整，也就是倒序
		return o1 < o2 ? -1 : 1; //o1小于o2，返回-1，说明不调整顺序，也就是小的还在前面，也就是升序
	}
});
```
### 1记为调整顺序也就是true；-1记为不调整顺序也就是false
## 关于Thompson采样和Beta分布
- Thompson采样采用Beta分布来描述收益率的分布，对于一个item来说，用户点击了一次wins + 1，用户没点的话，lose + 1
- betaSample(win,lose) -> 预估出一个item带来的收益 -> 按照这个revenue进行倒排可以选出收益item的topN
## 关于Git
- 查看本地分支和追踪情况：git remote show origin：可以看到一些stale的分支，这是远程已经删除的分支，但没同步到你的机器
- 使用 git remote prune origin去同步远程分支
- 最后使用 git branch -D 本地分支来删除本地分支
## 关于Spark的作业调度模型
- 每一个action算子提交job
- 根据job的宽窄依赖划分stage
- 根据stage中RDD的partition划分task
- Driver进程分发task到worker节点，Executor进程负责执行task
## 关于Spark中的累加器和广播变量
### 累加器
- Spark在操作和传递一个函数时，比如map，reduce等等，它会在远程集群中的一个节点执行，且操作的是**变量的副本**，且这些副本不能传回Driver进程，因此结果Driver进程拿不到，所以累机器和共享变量应运而生
- 累加器：Accumulator，Spark中的累加器主要有两种，Double和Long，还有个collection
 ```scala
 val doubleAcc = sc.doubleAccumulator
 val longAcc = sc.longAccumulator
 val collectionAcc = sc.collectionAccumulator
 doubleAcc.add(1.0)
 ```
**有名字和没有名字的累加器的区别在于，是否可以在WebUI上看到**
**由于Spark是lazy加载的，所以需要一个action算子提交job之后，累加器才会计算，注意，只能提交一次，否则会出现多加的情况，如果不得不提交两次，可以将前一次的结果通过持久化策略保存下来，避免计算两次**
**自定义累加器需extends AccumulatorV2，且使用时向sc注册**
### 广播变量
- 什么时候使用广播变量？比如Driver上面有一张表，其他节点运行的task都需要join这张表，好的方式是将这张表copy到每个节点，本地join，这就是广播变量
- 广播变量将变量广播到每个节点而不是task。因为每个task是一个线程，同一个Executor进程的task同属于一个application，，因此广播到每个节点即可。
## 关于j.u.c中的阻塞队列
### 阻塞队列有这么几个方法：
```Java
queue.add(); //内部调用offer，当队列满了的时候，抛出异常
queue.offer(); // 向队尾添加元素，当队列满了的时候，返回false
queue.put(); // 队列满了，会等待
queue.remove(); // 对应add
queue.poll(); // 对应offer，删除队首的元素
queue.take(); // 对应put
```
- ArrayBlockingQueue:内部基于数组实现，读写不分离，默认构造方法需要传递参数表示容量
- LinkedBlockingQueue:内部基于链表实现，读写分离，默认构造方法不需要传参但不代表其实无界的阻塞队列，它默认的界限是**Integer.MAX_VALUE**
- PriorityBlockingQueue:是一个带优先级的有界阻塞队列(**默认的容量是11**)，可以实现自定义排序
- DelayQueue:元素需要实现Delayed接口，无界
- SynchronousQueue:只存储一个元素；无界非缓存队列
## Java内存模型
### 为什么要提出Java内存模型(Java Memory Model)：为了屏蔽掉硬件和操作系统对内存访问速度上的差异，真正实现Java的跨平台
### 有以下三个规范：
- Java 内存模型规定所有的变量存在主内存（虚拟机内存的一部分）每条线程还有自己的工作内存 线程的工作内存保存了该线程使用到的变量和主内存副本拷贝，线程对变量的所有操作（读取或者赋值）都必须在工作内存，不能直接读写主内存的变量
- 不同线程之间的内存无法直接访问
- 线程间变量值的传递都需要通过主内存
## 关于Kafka的写入数据、丢消息以及重复消费
### 写入消息时候的ACK
- 0：producer将消息发到leader partition就完事，不关心leader partition是否保存成功，可能丢数据
- 1：当写Leader partition成功后就返回,其他的replica都是通过fetcher去同步的,所以kafka是异步写，主备切换可能丢数据。
- -1[ALL]：要等到isr里所有partition同步成功，才能返回成功，延时取决于最慢的机器。强一致，不会丢数据。
- 丢消息产生的原因以及解决方法：Producer向Leader Partition写数据，写完之后，Leader立刻挂了，消息永久丢失，且此时ACK设置的是0。解决方法：将ACK设置1
- 重复消费的产生原因以及解决方法：由于网络原因，导致生产者提交消息接收不到提交成功的反馈，导致消息重传；消费者没有返回消费成功反馈，重复拉取消息消费；
	- 将消息进行落库场景，例如将订单消息进行落库， 根据消息的不重复数据在表中建立这个数据字段的唯一键约束，比如订单号，同一个订单，第一次插入成功，根据唯一约束第二次插入就失败
	- 接到消息写redis场景，调用set覆盖缓存，天然幂等处理
	- 状态变更类消息，比如订单有三个状态，订单创建、订单支付、订单发货、订单完成，每个state状态对应一个int类型值，消息的state和db相同（反查数据库），不处理；不相同则更新数据表
### 为什么要使用消息队列？
- 流量削峰和缓冲：上游系统有突发流量，而下游系统扛不住瞬时大流量的冲击，或者说下游没有足够的资源来保证冗余，kafka相当于起到一个缓冲作用，把上游系统的消息保存在kafka中，下游系统可以按照自己的节奏来处理。
- 系统间解耦和扩展：将系统间复杂的调用关系解耦出来，多方可以自行决定是否接入kafka来消费信息。
- 异步通信：消息生产者可以将消息存入kafka，消息端可以不用立即处理消息，在需要的时候进行处理。
- 局部顺序消费保证：kafka的partition局部有序，保证了消息是按照顺序排序。
## 星型模型和雪花模型
### 事实表和维度表
- 事实表：存储有事实记录的表，比如系统日志等等
- 维度表：保存维度的属性值，比如日期表、地区表等
### 星型模型
- 一张事实表，以及零到多个维度表，事实表和维度表通过主外键关系相关联，维度表之间无关联
### 雪花模型
- 将星型模型中的某些维度表抽取成为更细粒度的维度表，并让维度之间关联
## ACL Access Control List
## 关于Spark中的aggregateByKey
```Scala
val conf = new SparkConf()
    val sc = new SparkContext(conf)

    val data = sc.parallelize(List(("13909029812",("20170507","http://www.baidu.com")),("18089376778",("20170401","http://www.google.com")),("18089376778",("20170508","http://www.taobao.com")),("13909029812",("20170507","http://www.51cto.com"))
    ))

    data.aggregateByKey(scala.collection.mutable.Set[(String, String)]())((set, item) => {
      set += item
    }, (set1, set2) => set1 union set2).mapValues(x => x.toIterable).collect
```
- 第一个参数：new一个Set集合
- 第二个参数：将value塞进set里面
- 第三个参数：set之间做规约
## Java中的内存泄露
### 指程序中动态分配内存给一些临时对象，但是对象不会被GC所回收，它始终占用内存。即被分配的对象可达但已无用。
## 设计模式(单例、生产者消费者)
### 单例模式的几种代码实现
```Java
// 懒汉模式(无线程安全问题)
public class Singleton{
	private Singletion)(){

	}
	private static Singletion s = new Singleton();
	public Singleton getInstance(){
		return s;
	}
}
```
```Java
// 饿汉模式(存在线程安全问题)
public class Singleton{
	private Singleton(){

	}
	private static Singleton s = null;
	public Singleton getInstance(){
		if (null == s){
			s = new Singleton();
		}
		return s;
	}
}
```
```Java
// 双重校验
public class Singleton{
	private static volatile Singleton s = null;
	private Singleton(){

	}
	public Singleton getInstance(){
		if (null == s){ // 第一重校验，提高效率，别上来就上锁
			synchronized (Singleton.class){
				if (null == s){ // 第二重校验，防止new两次
					s = new Singleton();
				}
			}
		}
		return s;
	}
}
```
```Java
// 静态内部类，由JVM实现线程安全，也能做到类的延迟加载
public class Singleton{
	private Singleton(){

	}
	private static class SingletonHolder{
		private static Singleton s = new Singleton();
	}
	public Singleton getInstance(){
		return SingletonHolder.s;
	}
}
```